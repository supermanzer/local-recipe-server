{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RealPython NLTK Tutorial\n",
    "---\n",
    "Learning the basics of the NLTK module for Natural Language Processessing following this tutorial.\n",
    "https://realpython.com/nltk-nlp-python/\n",
    "This focuses mostly on text preprocessing to faciliate better categorization and analysis.\n",
    "\n",
    "\n",
    "## Purpose\n",
    "The reason for familiarizing myself with this Python package and general area of machine learning is to provide the text categoziation functionality necessary for my [Reicpes Appliction](https://github.com/supermanzer/local-recipe-server)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages and define constants\n",
    "import nltk\n",
    "import numpy as np\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing\n",
    "Tokenizing is the process of splitting text by word, sentence, or group of sentences.  This can be useful in segmenting individual ingredients and steps in the aforemetioned app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word & Sentence Tokenization\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# Providing a basic sample\n",
    "example_string = \"\"\"\n",
    "Muad'Dib learned rapidly because his first training was in how to learn.\n",
    "And the first lesson of all was the basic trust that he could learn.\n",
    "It's shocking to find how many people do not believe they can learn,\n",
    "and how many more believe learning to be difficult.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\nMuad'Dib learned rapidly because his first training was in how to learn.\",\n",
       " 'And the first lesson of all was the basic trust that he could learn.',\n",
       " \"It's shocking to find how many people do not believe they can learn,\\nand how many more believe learning to be difficult.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting up our sample string by sentence.\n",
    "sent_tokenize(example_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Muad'Dib\",\n",
       " 'learned',\n",
       " 'rapidly',\n",
       " 'because',\n",
       " 'his',\n",
       " 'first',\n",
       " 'training',\n",
       " 'was',\n",
       " 'in',\n",
       " 'how',\n",
       " 'to',\n",
       " 'learn',\n",
       " '.',\n",
       " 'And',\n",
       " 'the',\n",
       " 'first',\n",
       " 'lesson',\n",
       " 'of',\n",
       " 'all',\n",
       " 'was',\n",
       " 'the',\n",
       " 'basic',\n",
       " 'trust',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'learn',\n",
       " '.',\n",
       " 'It',\n",
       " \"'s\",\n",
       " 'shocking',\n",
       " 'to',\n",
       " 'find',\n",
       " 'how',\n",
       " 'many',\n",
       " 'people',\n",
       " 'do',\n",
       " 'not',\n",
       " 'believe',\n",
       " 'they',\n",
       " 'can',\n",
       " 'learn',\n",
       " ',',\n",
       " 'and',\n",
       " 'how',\n",
       " 'many',\n",
       " 'more',\n",
       " 'believe',\n",
       " 'learning',\n",
       " 'to',\n",
       " 'be',\n",
       " 'difficult',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting up sample string by word\n",
    "word_tokenize(example_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'else' after 'if' expression (1413257316.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [8]\u001b[0;36m\u001b[0m\n\u001b[0;31m    filtered_list = [word for words_in_quote if word.casefold() not in stop_words]\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected 'else' after 'if' expression\n"
     ]
    }
   ],
   "source": [
    "# Filtering stop words\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "worf_quote = \"Sir, I protest.  I am not a merry man\"\n",
    "words_in_quote = word_tokenize(worf_quote)\n",
    "words_in_quote\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_list = [word for words_in_quote if word.casefold() not in stop_words]\n",
    "filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LOcalRecipeNotebooks",
   "language": "python",
   "name": "localrecipenotebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
